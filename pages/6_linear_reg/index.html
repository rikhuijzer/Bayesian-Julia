<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/Bayesian-Julia/libs/katex/katex.min.css"> <link rel=stylesheet  href="/Bayesian-Julia/libs/highlight/github.min.css"> <link rel=stylesheet  href="/Bayesian-Julia/css/jtd.css"> <link rel=icon  href="/Bayesian-Julia/assets/favicon.ico"> <title>Bayesian Linear Regression</title> <div class=page-wrap > <div class=side-bar > <div class=header > <a href="/Bayesian-Julia/" class=title > Bayesian Stats </a> </div> <label for=show-menu  class=show-menu >MENU</label> <input type=checkbox  id=show-menu  role=button > <div class=menu  id=side-menu > <ul class=menu-list > <li class="menu-list-item "><a href="/Bayesian-Julia/" class="menu-list-link ">Home</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/1_why_Julia/" class="menu-list-link ">1. Why Julia?</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/2_bayes_stats/" class="menu-list-link ">2. What is Bayesian Statistics?</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/3_prob_dist/" class="menu-list-link ">3. Common Probability Distributions</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/4_Turing/" class="menu-list-link ">4. How to use Turing</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/5_MCMC/" class="menu-list-link ">5. Markov Chain Monte Carlo (MCMC)</a> <li class="menu-list-item active"><a href="/Bayesian-Julia/pages/6_linear_reg/" class="menu-list-link active">6. Bayesian Linear Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/7_logistic_reg/" class="menu-list-link ">7. Bayesian Logistic Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/8_count_reg/" class="menu-list-link ">8. Bayesian Regression with Count Data</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/9_robust_reg/" class="menu-list-link ">9. Robust Bayesian Regression</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/10_multilevel_models/" class="menu-list-link ">10. Multilevel Models</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/11_Turing_tricks/" class="menu-list-link ">11. Computational Tricks with Turing</a> <li class="menu-list-item "><a href="/Bayesian-Julia/pages/12_epi_models/" class="menu-list-link ">12. Bayesian Epidemiological Models</a> </ul> </div> <div class=footer > <a href="https://www.julialang.org"><img style="height:50px;padding-left:10px;margin-bottom:15px;" src="https://julialang.org/assets/infra/logo.svg" alt="Julia Logo"></a> </div> </div> <div class=main-content-wrap > <div class=main-content > <div class=main-header > <a id=github  href="https://github.com/storopoli/Bayesian-Julia">Code on GitHub</a> </div> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-186284914-6"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-186284914-6'); </script> <div class=franklin-content ><div class=franklin-toc ><ol><li><a href="#linear_regression">Linear Regression</a><li><a href="#example_-_childrens_iq_score">Example - Children&#39;s IQ Score</a><li><a href="#references">References</a></ol></div> <h1 id=bayesian_linear_regression ><a href="#bayesian_linear_regression" class=header-anchor >Bayesian Linear Regression</a></h1> <blockquote> <p>&quot;All models are wrong but some are useful&quot; <br/> <br/> George Box &#40;Box, 1976&#41;</p> </blockquote> <p>This tutorial begins with a very provocative quote from the statistician <a href="https://en.wikipedia.org/wiki/George_E._P._Box">George Box</a> &#40;figure below&#41; on statistical models. Yes, all models are somehow wrong. But they are very useful. The idea is that the reality is too complex for us to understand when analyzing it in a naked and raw way. We need to somehow simplify it into individual components and analyze their relationships. But there is a danger here: any simplification of reality promotes loss of information in some way. Therefore, we always have a delicate balance between simplifications of reality through models and the inherent loss of information. Now you ask me: &quot;how are they useful?&quot; Imagine that you are in total darkness and you have a very powerful flashlight but with a narrow beam. Are you going to throw the flashlight away because it can&#39;t light everything around you and stay in the dark? You must use the flashlight to aim at interesting places in the darkness in order to illuminate them. You will never find a flashlight that illuminates everything with the clarity you need to analyze all the fine details of reality. Just as you will never find a unique model that will explain the whole reality around you. You need different flashlights just like you need different models. Without them you will be in total darkness.</p> <p><img src="/Bayesian-Julia/pages/images/george_box.jpg" alt="George Box" /></p> <p><div class=text-center ><em>George Box</em></div> <br/></p> <h2 id=linear_regression ><a href="#linear_regression" class=header-anchor >Linear Regression</a></h2> <p>Let&#39;s talk about a class of model known as linear regression. The idea here is to model a continuous dependent variable with a linear combination of independent variables.</p> <a id=linear_reg  class=anchor ></a>\[ \mathbf{y} = \alpha + \mathbf{X} \boldsymbol{\beta} + \epsilon \] <p>where:</p> <ul> <li><p>\(\mathbf{y}\) – dependent variable</p> <li><p>\(\alpha\) – intercept</p> <li><p>\(\boldsymbol{\beta}\) – coefficient vector</p> <li><p>\(\mathbf{X}\) – data matrix</p> <li><p>\(\epsilon\) – model error</p> </ul> <p>To estimate the \(\boldsymbol{\beta}\) coefficients we use a Gaussian/normal likelihood function. Mathematically the Bayesian regression model is:</p> \[ \begin{aligned} \mathbf{y} &\sim \text{Normal}\left( \alpha + \mathbf{X} \cdot \boldsymbol{\beta}, \sigma \right) \\ \alpha &\sim \text{Normal}(\mu_\alpha, \sigma_\alpha) \\ \boldsymbol{\beta} &\sim \text{Normal}(\mu_{\boldsymbol{\beta}}, \sigma_{\boldsymbol{\beta}}) \\ \sigma &\sim \text{Exponential}(\lambda_\sigma) \end{aligned} \] <p>Here we see that the likelihood function \(P(\mathbf{y} \mid \boldsymbol{\theta})\) is a normal distribution in which \(\mathbf{y}\) depends on the parameters of the model \(\alpha\) and \(\boldsymbol{\beta}\), in addition to having an error \(\sigma\). We condition \(\mathbf{y}\) onto the observed data \(\mathbf{X}\) by inserting \(\alpha + \mathbf{X} \cdot \boldsymbol{\beta}\) as the linear predictor of the model &#40;the mean \(\mu\) parameter of the model&#39;s Normal likelihood function, and \(\sigma\) is the variance parameter&#41;. What remains is to specify which are the priors of the model parameters:</p> <ul> <li><p>Prior Distribution of \(\alpha\) – Knowledge we possess regarding the model&#39;s intercept.</p> <li><p>Prior Distribution of \(\boldsymbol{\beta}\) – Knowledge we possess regarding the model&#39;s independent variables&#39; coefficients.</p> <li><p>Prior Distribution of \(\sigma\) – Knowledge we possess regarding the model&#39;s error. Important that the error can only be positive. In addition, it is intuitive to place a distribution that gives greater weight to values close to zero, but that also allows values that are far from zero, so a distribution with a long tail is welcome. Candidate distributions are \(\text{Exponential}\) which is only supported on positive real numbers &#40;so it solves the question of negative errors&#41; or \(\text{Cauchy}^+\) truncated to only positive numbers &#40;remembering that the distribution Cauchy is Student&#39;s \(t\) with degrees of freedom \(\nu = 1\)&#41;.</p> </ul> <p>Our goal is to instantiate a linear regression with the observed data &#40;\(\mathbf{y}\) and \(\mathbf{X}\)&#41; and find the posterior distribution of our model&#39;s parameters of interest &#40;\(\alpha\) and \(\boldsymbol{\beta}\)&#41;. This means to find the full posterior distribution of:</p> \[ P(\boldsymbol{\theta} \mid \mathbf{y}) = P(\alpha, \boldsymbol{\beta}, \sigma \mid \mathbf{y}) \] <p>This is easily accomplished with Turing:</p> <pre><code class=language-julia >using Turing
using Statistics: mean, std
using Random:seed&#33;
seed&#33;&#40;123&#41;

@model linreg&#40;X, y; predictors&#61;size&#40;X, 2&#41;&#41; &#61; begin
    #priors
    α ~ Normal&#40;mean&#40;y&#41;, 2.5 * std&#40;y&#41;&#41;
    β ~ filldist&#40;TDist&#40;3&#41;, predictors&#41;
    σ ~ Exponential&#40;1&#41;

    #likelihood
    y ~ MvNormal&#40;α .&#43; X * β, σ&#41;
end;</code></pre> <p>Here I am specifying very weakly informative priors:</p> <ul> <li><p>\(\alpha \sim \text{Normal}(\bar{\mathbf{y}}, 2.5 \cdot \sigma_{\mathbf{y}})\) – This means a normal distribution centered on <code>y</code>&#39;s mean with a standard deviation 2.5 times the standard deviation of <code>y</code>. That prior should with ease cover all possible values of \(\alpha\). Remember that the normal distribution has support over all the real number line \(\in (-\infty, +\infty)\).</p> <li><p>\(\boldsymbol{\beta} \sim \text{Student-}t(0,1,3)\) – The predictors all have a prior distribution of a Student-\(t\) distribution centered on 0 with variance 1 and degrees of freedom \(\nu = 3\). That wide-tailed \(t\) distribution will cover all possible values for our coefficients. Remember the Student-\(t\) also has support over all the real number line \(\in (-\infty, +\infty)\). Also the <code>filldist&#40;&#41;</code> is a nice Turing&#39;s function which takes any univariate or multivariate distribution and returns another distribution that repeats the input distribution.</p> <li><p>\(\sigma \sim \text{Exponential}(1)\) – A wide-tailed-positive-only distribution perfectly suited for our model&#39;s error.</p> </ul> <h2 id=example_-_childrens_iq_score ><a href="#example_-_childrens_iq_score" class=header-anchor >Example - Children&#39;s IQ Score</a></h2> <p>For our example, I will use a famous dataset called <code>kidiq</code> &#40;Gelman &amp; Hill, 2007&#41;, which is data from a survey of adult American women and their respective children. Dated from 2007, it has 434 observations and 4 variables:</p> <ul> <li><p><code>kid_score</code>: child&#39;s IQ</p> <li><p><code>mom_hs</code>: binary/dummy &#40;0 or 1&#41; if the child&#39;s mother has a high school diploma</p> <li><p><code>mom_iq</code>: mother&#39;s IQ</p> <li><p><code>mom_age</code>: mother&#39;s age</p> </ul> <p>Ok let&#39;s read our data with <code>CSV.jl</code> and output into a <code>DataFrame</code> from <code>DataFrames.jl</code>:</p> <pre><code class=language-julia >using DataFrames, CSV, HTTP

url &#61; &quot;https://raw.githubusercontent.com/storopoli/Bayesian-Julia/master/datasets/kidiq.csv&quot;
kidiq &#61; CSV.read&#40;HTTP.get&#40;url&#41;.body, DataFrame&#41;
describe&#40;kidiq&#41;</code></pre><pre><code class="plaintext code-output">Failed to precompile CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b] to /home/runner/.julia/compiled/v1.6/CSV/jl_4tnAOH.
</code></pre> <p>As you can see from the <code>describe&#40;&#41;</code> output, the mean children&#39;s IQ is around 87 while the mother&#39;s is 100. Also the mother&#39;s range from 17 to 29 years with mean of around 23 years old. Finally, note that 79&#37; of mothers have a high school diploma.</p> <p>Now let&#39;s us instantiate our model with the data:</p> <pre><code class=language-julia >X &#61; Matrix&#40;select&#40;kidiq, Not&#40;:kid_score&#41;&#41;&#41;
y &#61; kidiq&#91;:, :kid_score&#93;
model &#61; linreg&#40;X, y&#41;;</code></pre><pre><code class="plaintext code-output">UndefVarError: kidiq not defined
</code></pre> <p>And, finally, we will sample from the Turing model. We will be using the default <code>NUTS&#40;&#41;</code> sampler with <code>2_000</code> samples, but now we will sample from 4 Markov chains using multiple threads <code>MCMCThreads&#40;&#41;</code>:</p> <pre><code class=language-julia >chain &#61; sample&#40;model, NUTS&#40;&#41;, MCMCThreads&#40;&#41;, 2_000, 4&#41;
summarystats&#40;chain&#41;</code></pre><pre><code class="plaintext code-output">UndefVarError: model not defined
</code></pre> <p>We had no problem with the Markov chains as all the <code>rhat</code> are well below <code>1.01</code> &#40;or above <code>0.99</code>&#41;. Our model has an error <code>σ</code> of around 18. So it estimates IQ±9. The intercept <code>α</code> is the basal child&#39;s IQ. So each child has 22±9 IQ before we add the coefficients multiplied by the child&#39;s independent variables. And from our coefficients \(\boldsymbol{\beta}}\), we can see that the <code>quantile&#40;&#41;</code> tells us the uncertainty around their estimates:</p> <pre><code class=language-julia >quantile&#40;chain&#41;</code></pre><pre><code class="plaintext code-output">UndefVarError: chain not defined
</code></pre> <ul> <li><p><code>β&#91;1&#93;</code> – first column of <code>X</code>, <code>mom_hs</code>, has 95&#37; credible interval that is all over the place, including zero. So its effect on child&#39;s IQ is inconclusive.</p> <li><p><code>β&#91;2&#93;</code> – second column of <code>X</code>, <code>mom_iq</code>, has a 95&#37; credible interval from 0.46 to 0.69. So we expect that every increase in the mother&#39;s IQ is associated with a 0.46 to 0.69 increase in the child&#39;s IQ.</p> <li><p><code>β&#91;3&#93;</code> – third column of <code>X</code>, <code>mom_age</code>, has also 95&#37; credible interval that is all over the place, including zero. Like <code>mom_hs</code>, its effect on child&#39;s IQ is inconclusive.</p> </ul> <p>That&#39;s how you interpret 95&#37; credible intervals from a <code>quantile&#40;&#41;</code> output of a linear regression <code>Chains</code> object.</p> <h2 id=references ><a href="#references" class=header-anchor >References</a></h2> <p>Box, G. E. P. &#40;1976&#41;. Science and Statistics. Journal of the American Statistical Association, 71&#40;356&#41;, 791–799. https://doi.org/10.2307/2286841</p> <p>Gelman, A., &amp; Hill, J. &#40;2007&#41;. Data analysis using regression and multilevel/hierarchical models. Cambridge university press.</p> <div class=page-foot > <div class=copyright > Last modified: August 12, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div> </div> <!-- end of class page-wrap--> <script src="/Bayesian-Julia/libs/katex/katex.min.js"></script> <script src="/Bayesian-Julia/libs/katex/auto-render.min.js"></script> <script>renderMathInElement(document.body)</script> <script src="/Bayesian-Julia/libs/highlight/highlight.pack.js"></script> <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: ' '});</script>